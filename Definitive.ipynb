{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c0317-689e-4e01-976f-ffa90a2561b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerias\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize, FunctionTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    roc_auc_score, confusion_matrix, cohen_kappa_score\n",
    ")\n",
    "\n",
    "from sklearn.feature_selection import chi2, RFE, SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15976e8-3f49-4bb6-9bb5-43ed6c1d2b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos las funciones\n",
    "# Funcion para crear las DF necesarios para cada columna\n",
    "def prepare_filtered_datasets(df):\n",
    "    filters = {\n",
    "        \"sinovitis\": [\"Assay\", \"deposito\", \"microcristales\", \"suero\", \"sexo\", \"edad\",\"ac_urico\"],\n",
    "        \"deposito\": [\"Assay\", \"microcristales\", \"sinovitis\", \"suero\", \"sexo\", \"edad\",\"ac_urico\"],\n",
    "        \"microcristales\": [\"Assay\", \"deposito\", \"sinovitis\", \"suero\", \"sexo\", \"edad\",\"ac_urico\"]\n",
    "    }\n",
    "\n",
    "    datasets = {}\n",
    "    for target, drop_cols in filters.items():\n",
    "        if target == 'sinovitis':\n",
    "            df['leucocito'] = df['leucocito'].fillna(df['leucocito'].median())\n",
    "        df_filtered = df.drop(columns=[col for col in drop_cols if col in df.columns])\n",
    "        df_filtered = df_filtered.dropna(subset=[target])\n",
    "        datasets[target] = df_filtered\n",
    "    return datasets\n",
    "\n",
    "def get_metrics(y_true, y_pred, y_proba, target, average='macro'):\n",
    "    metrics = {}\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if cm.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        vpn = tn / (tn + fn) if (tn + fn) > 0 else np.nan\n",
    "        metrics['VPN'] = round(vpn, 2)\n",
    "    else:\n",
    "        metrics['VPN'] = np.nan\n",
    "\n",
    "    # if target == 'microcristales':\n",
    "    #     clases = sorted(set(y_true))\n",
    "    #     y_true_bin = label_binarize(y_true, classes=clases)\n",
    "    #     for i, clase in enumerate(clases):\n",
    "    #         auc = roc_auc_score(y_true_bin[:, i], y_proba[:, i])\n",
    "    #         metrics[f'AUC_class_{clase}'] = round(auc, 2)\n",
    "            \n",
    "    metrics.update({\n",
    "        'Accuracy': round(accuracy_score(y_true, y_pred), 2),\n",
    "        'F1_macro': round(f1_score(y_true, y_pred, average=average), 2),\n",
    "        'F1_weighted': round(f1_score(y_true, y_pred, average='weighted'), 2),\n",
    "        'Precision (VPP)': round(precision_score(y_true, y_pred, average=average), 2),\n",
    "        'Recall_macro': round(recall_score(y_true, y_pred, average=average), 2),\n",
    "        'Recall_weighted': round(recall_score(y_true, y_pred, average='weighted'), 2),\n",
    "        'AUC_macro': round(roc_auc_score(y_true, y_proba, average=average, multi_class='ovo'), 2),\n",
    "        'AUC_weighted': round(roc_auc_score(y_true, y_proba, average='weighted', multi_class='ovo'), 2),\n",
    "        'Kappa': round(cohen_kappa_score(y_true, y_pred), 2)\n",
    "    })\n",
    "    return metrics\n",
    "\n",
    "def build_selector(method, k):\n",
    "    if method == 'all':\n",
    "        return 'passthrough'\n",
    "    if method == 'f_classif':\n",
    "        return SelectKBest(score_func=f_classif, k=k)\n",
    "    if method == 'chi2':\n",
    "        return SelectKBest(score_func=chi2, k=k)\n",
    "    if method == 'rfe':\n",
    "        return RFE(estimator=LogisticRegression(max_iter=1000), n_features_to_select=k)\n",
    "    if method == 'lasso':\n",
    "        return SelectFromModel(Lasso(alpha=0.01), max_features=k)\n",
    "    if method == 'ridge':\n",
    "        return SelectFromModel(Ridge(alpha=1.0, max_iter=1000))\n",
    "    raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "def run_pipeline_feature_selection(df, target_col, feature_counts=[10], methods=['all', 'f_classif'], models=None, output_dir='./plots'):\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    numeric_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "    results = []\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)\n",
    "\n",
    "    if models is None:\n",
    "        # Selección condicional del modelo de regresión logística\n",
    "        if target_col == 'microcristales':\n",
    "            logistic_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "        else:\n",
    "            logistic_model = LogisticRegression()\n",
    "\n",
    "        models = {\n",
    "            \"LogisticRegression\": logistic_model,\n",
    "            \"RandomForest\": RandomForestClassifier(random_state=42),\n",
    "            \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "            \"SVM\": SVC(kernel='linear', probability=True, random_state=42),\n",
    "            \"NaiveBayes\": GaussianNB(),\n",
    "            \"KNN\": KNeighborsClassifier(),\n",
    "            \"LightGBM\": LGBMClassifier(random_state=42),\n",
    "            \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "            \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42)\n",
    "        }\n",
    "\n",
    "    importance_dir = os.path.join(output_dir, 'feature_importance')\n",
    "    os.makedirs(importance_dir, exist_ok=True)\n",
    "\n",
    "    for method in methods:\n",
    "        for k in feature_counts:\n",
    "            selector = build_selector(method, k)\n",
    "            if method == 'chi2':\n",
    "                positive_transform = FunctionTransformer(lambda x: (x - np.min(x, axis=0)) + 1e-9, validate=False)\n",
    "                preprocessor = ColumnTransformer(transformers=[\n",
    "                    ('num', Pipeline([\n",
    "                        ('positive', positive_transform),\n",
    "                        ('selector', selector)\n",
    "                    ]), numeric_features)\n",
    "                ])\n",
    "            else:\n",
    "                preprocessor = ColumnTransformer(transformers=[\n",
    "                    ('num', Pipeline([\n",
    "                        ('scaler', StandardScaler()),\n",
    "                        ('selector', selector)\n",
    "                    ]), numeric_features)\n",
    "                ])\n",
    "\n",
    "            for name, model in models.items():\n",
    "                pipe = Pipeline([\n",
    "                    ('preprocessor', preprocessor),\n",
    "                    ('classifier', model)\n",
    "                ])\n",
    "                try:\n",
    "                    pipe.fit(X_train, y_train)\n",
    "                    y_pred = pipe.predict(X_test)\n",
    "                    y_proba = pipe.predict_proba(X_test)\n",
    "                    y_proba_input = y_proba[:, 1] if y_proba.shape[1] == 2 else y_proba\n",
    "\n",
    "                    metrics = get_metrics(y_test, y_pred, y_proba_input, target=target_col)\n",
    "                    metrics.update({\n",
    "                        'Model': name,\n",
    "                        'Feature_Selection': method,\n",
    "                        'Num_Features': k\n",
    "                    })\n",
    "                    results.append(metrics)\n",
    "\n",
    "                    # Obtener nombres de variables seleccionadas\n",
    "                    fitted_selector = pipe.named_steps['preprocessor'].named_transformers_['num'].named_steps['selector']\n",
    "                    if hasattr(fitted_selector, 'get_support'):\n",
    "                        mask = fitted_selector.get_support()\n",
    "                        selected_features = [f for f, m in zip(numeric_features, mask) if m]\n",
    "                    else:\n",
    "                        selected_features = numeric_features\n",
    "\n",
    "                    model_final = pipe.named_steps['classifier']\n",
    "                    importances = None\n",
    "                    \n",
    "                    if hasattr(model_final, \"feature_importances_\"):\n",
    "                        importances = model_final.feature_importances_\n",
    "                    elif hasattr(model_final, \"coef_\"):\n",
    "                        coef = np.abs(model_final.coef_)\n",
    "                        importances = coef.mean(axis=0) if coef.ndim > 1 else coef.ravel()\n",
    "\n",
    "                    # Fallback: Permutation importance si no hay atributos nativos\n",
    "                    if importances is None:\n",
    "                        try:\n",
    "                            # X_test procesado (ya transformado por preprocessor)\n",
    "                            X_test_transformed = pipe.named_steps['preprocessor'].transform(X_test)\n",
    "                            result = permutation_importance(\n",
    "                                model_final,\n",
    "                                X_test_transformed,\n",
    "                                y_test,\n",
    "                                n_repeats=10,\n",
    "                                random_state=42,\n",
    "                                scoring='accuracy',\n",
    "                                n_jobs=-1  # Usa todos los núcleos disponibles\n",
    "                            )\n",
    "                            importances = result.importances_mean\n",
    "                        except Exception as e:\n",
    "                            print(f\"⚠️ No se pudo calcular permutation_importance para {name} ({method}, k={k}): {e}\")\n",
    "\n",
    "\n",
    "                    if importances is not None and selected_features is not None and len(importances) == len(selected_features):\n",
    "                        imp_df = pd.DataFrame({\n",
    "                            'Feature': selected_features,\n",
    "                            'Importance': importances\n",
    "                        }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "                        imp_df = imp_df.head(20)\n",
    "\n",
    "                        column_map = {\n",
    "                            \"microcristales\": \"Microcrystals\",\n",
    "                            \"deposito\": \"Deposits\",\n",
    "                            \"sinovitis\": \"Synovitis\"\n",
    "                        }\n",
    "\n",
    "                        if target_col in column_map:\n",
    "                            target_col = column_map[target_col]\n",
    "\n",
    "                        plt.figure(figsize=(10, 6))\n",
    "                        sns.barplot(data=imp_df, x='Importance', y='Feature')\n",
    "                        plt.title(f'Feature selection — {target_col} — {name} ({method}, k={k})')\n",
    "                        plt.tight_layout()\n",
    "\n",
    "                        fname = f\"{target_col}_{name}_{method}_k{k}_importance.png\"\n",
    "                        fpath = os.path.join(importance_dir, fname)\n",
    "                        plt.savefig(fpath)\n",
    "                        plt.close()\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Error con modelo {name}, método {method}, k={k}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def save_boxplots(results_df, target_name, metrics=None, by_fields=[\"Model\", \"Feature_Selection\"], output_dir=\"./plots\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    if metrics is None:\n",
    "        metrics = [\"F1_macro\", 'F1_weighted', 'Recall_macro', 'Recall_weighted', 'AUC_macro', 'AUC_weighted', \"Kappa\"]\n",
    "        \n",
    "    for metric in metrics:\n",
    "        for by in by_fields:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sns.boxplot(data=results_df, x=by, y=metric)\n",
    "            plt.title(f\"{metric} por {by} — {target_name}\")\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.grid(True, axis='y')\n",
    "            plt.tight_layout()\n",
    "\n",
    "            filename = f\"{output_dir}/{target_name}_{metric}_by_{by}.png\"\n",
    "            plt.savefig(filename)\n",
    "            plt.close()\n",
    "\n",
    "def run_all_experiments(df):\n",
    "    datasets = prepare_filtered_datasets(df)\n",
    "    feature_methods = ['all', 'f_classif', 'chi2', 'rfe', 'lasso', 'ridge']\n",
    "    feature_counts = [5, 10, 15, 20]\n",
    "\n",
    "    results = {}\n",
    "    for target, df_clean in datasets.items():\n",
    "        df_clean = df_clean.drop(df_clean.columns[0], axis=1) #Remove sample ID\n",
    "        print(df_clean.columns)\n",
    "        print(f\"\\n▶️ Ejecutando para target: {target.upper()} — {df_clean.shape[0]} muestras, {df_clean.shape[1]-1} features\")\n",
    "        try:\n",
    "            result = run_pipeline_feature_selection(\n",
    "                df=df_clean,\n",
    "                target_col=target,\n",
    "                feature_counts=feature_counts,\n",
    "                methods=feature_methods,\n",
    "                output_dir=f\"./plots/{target}\"\n",
    "            )\n",
    "            results[target] = result\n",
    "            result.to_csv(f\"./plots/results_{target}.csv\", index=False)\n",
    "            result[result['Kappa'] > 0.5].to_csv(f\"./plots/results_{target}_filter_kappa.csv\", index=False)\n",
    "            save_boxplots(result, target_name=target, output_dir=f\"./plots/{target}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error ejecutando target {target}: {e}\")\n",
    "            results[target] = None\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bcc28d-ebef-4c08-8e9e-ba9bd85f9bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos los datos\n",
    "df = pd.read_csv(\"./datos/combinacion.csv\",sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a29ca88-c1e5-4e25-91b6-fb3bd33a2666",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = run_all_experiments(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
